{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Pandas, part 2 </center>\n",
    "### By the end of this talk, you will be able to\n",
    "   - modify/clean columns\n",
    "   - evaluate the runtime of your scripts\n",
    "   - merge and append data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  <font color='LIGHTGRAY'>By the end of this talk, you will be able to</font>\n",
    "   - **modify/clean columns**\n",
    "   - **evaluate the runtime of your scripts**\n",
    "   -  <font color='LIGHTGRAY'>merge and append data frames</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is data cleaning?\n",
    "- the data you scrape from sites are often not in a format you can directly work with\n",
    "    - the temp column in weather.csv contains the temperature value but also other strings\n",
    "    - the year column in imdb.csv contains the year the movie came out but also - or () and roman numbers\n",
    "- data cleaning means that you bring the data in a format that's easier to analyze/visualize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How is it done?\n",
    "- you read in your data into a pandas data frame and either \n",
    "    - modify the values of a column\n",
    "    - create a new column that contains the modified values\n",
    "- either works, I'll show you how to do both\n",
    "- ADVICE: when you save the modified data frame, it is usually good practice to not overwrite the original csv or excel file that you scraped. \n",
    "    - save the modified data into a new file instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to modify a column\n",
    "- there are several ways to do this\n",
    "    - with a for loop\n",
    "    - with a list comprehension\n",
    "    - using the .apply method\n",
    "- we will compare run times\n",
    "    - investigate which approach is faster\n",
    "    - important when you work with large datasets (>1,000,000 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The task: runtime column in imdb.csv\n",
    "- the column is string in the format 'n min' where n is the length of the movie in minutes\n",
    "- for plotting purposes, it is better if the runtime is not a string but a number (float or int)\n",
    "    - you can't create a histogram of runtime using strings\n",
    "- task: clean the runtime column and convert it to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approach 1: for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "import pandas as pd\n",
    "df_imdb = pd.read_csv('../week_3/data/imdb.csv')\n",
    "print(df_imdb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time() # start the clock\n",
    "\n",
    "for i in range(100): # repeat everything 100 times to get better estimate of elapsed time\n",
    "    # the actual code to clean the runtime column comes here\n",
    "    runtime_lst = []\n",
    "    for x in df_imdb['runtime']:\n",
    "        if type(x) == str:\n",
    "            runtime = float(x[:-4].replace(',',''))\n",
    "        else:\n",
    "            runtime = 0e0\n",
    "        runtime_lst.append(runtime)\n",
    "    df_imdb['runtime min'] = runtime_lst\n",
    "    \n",
    "end = time.time() # stop the timer\n",
    "\n",
    "print('cpu time = ',end-start,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # start the clock\n",
    "\n",
    "for i in range(100): # repeat everything 100 times to get better estimate of elapsed time\n",
    "    # the actual code to clean the runtime column comes here\n",
    "    df_imdb['runtime min'] = [float(x[:-4].replace(',','')) if type(x) == str else 0e0 for x in df_imdb['runtime']]\n",
    "end = time.time() # stop the timer\n",
    "\n",
    "print('cpu time = ',end-start,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: the .apply method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_runtime(x):\n",
    "    if type(x) == str:\n",
    "        runtime = float(x[:-4].replace(',',''))\n",
    "    else:\n",
    "        runtime = 0e0\n",
    "    return  runtime\n",
    "\n",
    "start = time.time() # start the clock\n",
    "\n",
    "for i in range(100): # repeat everything 100 times to get better estimate of elapsed time\n",
    "    # the actual code to clean the runtime column comes here\n",
    "    df_imdb['runtime min'] = df_imdb['runtime'].apply(clean_runtime)\n",
    "end = time.time() # stop the timer\n",
    "\n",
    "print('cpu time = ',end-start,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- the for loop is slower\n",
    "- the list comprehension and the apply method are equally quick\n",
    "- it is down to personal preference to choose between list comprehension and .apply\n",
    "- **the same ranking is not quaranteed for a different task!**\n",
    "    - **always try a few different approaches if runtime is an issue (you work with large data)!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 1\n",
    "Clean the `temp` column in the `../week_3/data/weather.csv` file. The new temperature column should be an integer or a float. Work through at least one of the approaches we discussed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  <font color='LIGHTGRAY'>By the end of this talk, you will be able to</font>\n",
    "   - <font color='LIGHTGRAY'>modify/clean columns</font>\n",
    "   - <font color='LIGHTGRAY'>evaluate the runtime of your scripts</font>\n",
    "   -  **merge and append data frames**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to merge dataframes?\n",
    "\n",
    "Merge - data are distributed in multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# We have two datasets from two hospitals\n",
    "\n",
    "hospital1 = {'ID':['ID1','ID2','ID3','ID4','ID5','ID6','ID7'],'col1':[5,8,2,6,0,2,5],'col2':['y','j','w','b','a','b','t']}\n",
    "df1 = pd.DataFrame(data=hospital1)\n",
    "print(df1)\n",
    "\n",
    "hospital2 = {'ID':['ID2','ID5','ID6','ID10','ID11'],'col3':[12,76,34,98,65],'col2':['q','u','e','l','p']}\n",
    "df2 = pd.DataFrame(data=hospital2)\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# we are interested in only patients from hospital1\n",
    "#df_left = df1.merge(df2,how='left',on='ID') # IDs from the left dataframe (df1) are kept\n",
    "#print(df_left)\n",
    "\n",
    "# we are interested in only patients from hospital2\n",
    "#df_right = df1.merge(df2,how='right',on='ID') # IDs from the right dataframe (df2) are kept\n",
    "#print(df_right)\n",
    "\n",
    "# we are interested in patiens who were in both hospitals\n",
    "#df_inner = df1.merge(df2,how='inner',on='ID') # merging on IDs present in both dataframes\n",
    "#print(df_inner)\n",
    "\n",
    "# we are interested in all patients who visited at least one of the hospitals\n",
    "#df_outer = df1.merge(df2,how='outer',on='ID')  # merging on IDs present in any dataframe\n",
    "#print(df_outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to append dataframes?\n",
    "\n",
    "Append - new data comes in over a period of time. E.g., one file per month/quarter/fiscal year etc.\n",
    "\n",
    "\n",
    "You want to combine these files into one data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_append = df1.append(df2) # note that rows with ID2, ID5, and ID6  are duplicated! Indices are duplicated too.\n",
    "#print(df_append)\n",
    "\n",
    "df_append = df1.append(df2,ignore_index=True) # note that rows with ID2, ID5, and ID6  are duplicated! \n",
    "#print(df_append)\n",
    "\n",
    "d3 = {'ID':['ID23','ID94','ID56','ID17'],'col1':['rt','h','st','ne'],'col2':[23,86,23,78]}\n",
    "df3 = pd.DataFrame(data=d3)\n",
    "#print(df3)\n",
    "\n",
    "df_append = df1.append([df2,df3],ignore_index=True) # multiple dataframes can be appended to df1\n",
    "print(df_append)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Exercise 2\n",
    "- Create three data frames from raw_data_1, 2, and 3.\n",
    "- Append the first two data frames and assign it to df_append.\n",
    "- Merge the third data frame with df_append such that only subject_ids from df_append are present. \n",
    "- Assign the new data frame to df_merge. \n",
    "- How many rows and columns do we have in df_merge?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_data_1 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "\n",
    "raw_data_2 = {\n",
    "        'subject_id': ['6', '7', '8', '9', '10'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "\n",
    "raw_data_3 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}\n",
    "\n",
    "# add your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Always check that the resulting dataframe is what you wanted to end up with!\n",
    "- small toy datasets are ideal to test your code.\n",
    "\n",
    "### If you need to do a more complicated dataframe operation, check out pd.concat()!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
